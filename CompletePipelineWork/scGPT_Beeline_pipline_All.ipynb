{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_HOME'] = '/usr/lib/cuda'\n",
    "os.environ['CUDA_PATH'] = '/usr/lib/cuda/bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dostofizky/anaconda3/envs/nrnb/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/dostofizky/anaconda3/envs/nrnb/lib/python3.10/site-packages/scgpt/model/model.py:21: UserWarning: flash_attn is not installed\n",
      "  warnings.warn(\"flash_attn is not installed\")\n",
      "/home/dostofizky/anaconda3/envs/nrnb/lib/python3.10/site-packages/scgpt/model/multiomic_model.py:19: UserWarning: flash_attn is not installed\n",
      "  warnings.warn(\"flash_attn is not installed\")\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import warnings\n",
    "from anndata import AnnData\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import gseapy as gp\n",
    "\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext._torchtext import (\n",
    "    Vocab as VocabPybind,\n",
    ")\n",
    "\n",
    "sys.path.insert(0, \"../\")\n",
    "import scgpt as scg\n",
    "from scgpt.tasks import GeneEmbedding\n",
    "from scgpt.tokenizer.gene_tokenizer import GeneVocab\n",
    "from scgpt.model import TransformerModel\n",
    "from scgpt.preprocess import Preprocessor\n",
    "from scgpt.utils import set_seed \n",
    "\n",
    "os.environ[\"KMP_WARNINGS\"] = \"off\"\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "pad_token = \"<pad>\"\n",
    "special_tokens = [pad_token, \"<cls>\", \"<eoc>\"]\n",
    "n_hvg = 1200\n",
    "n_bins = 51\n",
    "mask_value = -1\n",
    "pad_value = -2\n",
    "n_input_bins = n_bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Load pre-trained model and dataset\n",
    "## 1.1 Load pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume model from /home/dostofizky/Documents/NRNB238/models/scGPT_all_model/scGPT_human/best_model.pt, the model args will override the config /home/dostofizky/Documents/NRNB238/models/scGPT_all_model/scGPT_human/args.json.\n"
     ]
    }
   ],
   "source": [
    "# Specify model path; here we load the pre-trained scGPT blood model\n",
    "model_dir = Path(\"/home/dostofizky/Documents/NRNB238/models/scGPT_all_model/scGPT_human\")\n",
    "model_config_file = model_dir / \"args.json\"\n",
    "model_file = model_dir / \"best_model.pt\"\n",
    "vocab_file = model_dir / \"vocab.json\"\n",
    "\n",
    "vocab = GeneVocab.from_file(vocab_file)\n",
    "for s in special_tokens:\n",
    "    if s not in vocab:\n",
    "        vocab.append_token(s)\n",
    "\n",
    "# Retrieve model parameters from config files\n",
    "with open(model_config_file, \"r\") as f:\n",
    "    model_configs = json.load(f)\n",
    "print(\n",
    "    f\"Resume model from {model_file}, the model args will override the \"\n",
    "    f\"config {model_config_file}.\"\n",
    ")\n",
    "embsize = model_configs[\"embsize\"]\n",
    "nhead = model_configs[\"nheads\"]\n",
    "d_hid = model_configs[\"d_hid\"]\n",
    "nlayers = model_configs[\"nlayers\"]\n",
    "n_layers_cls = model_configs[\"n_layers_cls\"]\n",
    "\n",
    "gene2idx = vocab.get_stoi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading params encoder.embedding.weight with shape torch.Size([60697, 512])\n",
      "Loading params encoder.enc_norm.weight with shape torch.Size([512])\n",
      "Loading params encoder.enc_norm.bias with shape torch.Size([512])\n",
      "Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])\n",
      "Loading params value_encoder.linear1.bias with shape torch.Size([512])\n",
      "Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params value_encoder.linear2.bias with shape torch.Size([512])\n",
      "Loading params value_encoder.norm.weight with shape torch.Size([512])\n",
      "Loading params value_encoder.norm.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])\n",
      "Loading params decoder.fc.0.weight with shape torch.Size([512, 512])\n",
      "Loading params decoder.fc.0.bias with shape torch.Size([512])\n",
      "Loading params decoder.fc.2.weight with shape torch.Size([512, 512])\n",
      "Loading params decoder.fc.2.bias with shape torch.Size([512])\n",
      "Loading params decoder.fc.4.weight with shape torch.Size([1, 512])\n",
      "Loading params decoder.fc.4.bias with shape torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (encoder): GeneEncoder(\n",
       "    (embedding): Embedding(60697, 512, padding_idx=60694)\n",
       "    (enc_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (value_encoder): ContinuousValueEncoder(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (linear1): Linear(in_features=1, out_features=512, bias=True)\n",
       "    (activation): ReLU()\n",
       "    (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.5, inplace=False)\n",
       "        (dropout2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): ExprDecoder(\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=512, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (cls_decoder): ClsDecoder(\n",
       "    (_decoder): ModuleList(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (out_layer): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       "  (sim): Similarity(\n",
       "    (cos): CosineSimilarity()\n",
       "  )\n",
       "  (creterion_cce): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "ntokens = len(vocab)  # size of vocabulary\n",
    "model = TransformerModel(\n",
    "    ntokens,\n",
    "    embsize,\n",
    "    nhead,\n",
    "    d_hid,\n",
    "    nlayers,\n",
    "    vocab=vocab,\n",
    "    pad_value=pad_value,\n",
    "    n_input_bins=n_input_bins,\n",
    ")\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load(model_file))\n",
    "    print(f\"Loading all model params from {model_file}\")\n",
    "except:\n",
    "    # only load params that are in the model and match the size\n",
    "    model_dict = model.state_dict()\n",
    "    pretrained_dict = torch.load(model_file)\n",
    "    pretrained_dict = {\n",
    "        k: v\n",
    "        for k, v in pretrained_dict.items()\n",
    "        if k in model_dict and v.shape == model_dict[k].shape\n",
    "    }\n",
    "    for k, v in pretrained_dict.items():\n",
    "        print(f\"Loading params {k} with shape {v.shape}\")\n",
    "        model_dict.update(pretrained_dict)\n",
    "        model.load_state_dict(model_dict)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Load dataset of interest\n",
    "## The Immune Human dataset can be downloaded via this link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify data path; here we load the Immune Human dataset\n",
    "data_dir = Path(\"../data\")\n",
    "adata = sc.read(\n",
    "    str(data_dir / \"Immune_ALL_human.h5ad\"), cache=True\n",
    ")  # 33506 × 12303\n",
    "ori_batch_col = \"batch\"\n",
    "adata.obs[\"celltype\"] = adata.obs[\"final_annotation\"].astype(str)\n",
    "data_is_raw = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - Filtering genes by counts ...\n",
      "scGPT - INFO - Normalizing total counts ...\n",
      "scGPT - INFO - Subsetting highly variable genes ...\n",
      "scGPT - INFO - Binning data ...\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data following the scGPT data pre-processing pipeline\n",
    "preprocessor = Preprocessor(\n",
    "    use_key=\"X\",  # the key in adata.layers to use as raw data\n",
    "    filter_gene_by_counts=3,  # step 1\n",
    "    filter_cell_by_counts=False,  # step 2\n",
    "    normalize_total=1e4,  # 3. whether to normalize the raw data and to what sum\n",
    "    result_normed_key=\"X_normed\",  # the key in adata.layers to store the normalized data\n",
    "    log1p=data_is_raw,  # 4. whether to log1p the normalized data\n",
    "    result_log1p_key=\"X_log1p\",\n",
    "    subset_hvg=n_hvg,  # 5. whether to subset the raw data to highly variable genes\n",
    "    hvg_flavor=\"seurat_v3\" if data_is_raw else \"cell_ranger\",\n",
    "    binning=n_bins,  # 6. whether to bin the raw data and to what number of bins\n",
    "    result_binned_key=\"X_binned\",  # the key in adata.layers to store the binned data\n",
    ")\n",
    "preprocessor(adata, batch_key=\"batch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Retrieve scGPT's gene embeddings\n",
    "\n",
    "Note that technically scGPT's gene embeddings are data independent. Overall, the pre-trained foundation model contains 30+K genes. Here for simplicity, we focus on a subset of HVGs specific to the data at hand.\n",
    "\n",
    "Then we save the Gene Embeddings in a .csv file to feed into the following algorithms in Beeline:\n",
    "1. PIDC\n",
    "2. GRNBoost2\n",
    "3. GENIE3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the data-independent gene embeddings from scGPT\n",
    "gene_ids = np.array([id for id in gene2idx.values()])\n",
    "gene_embeddings = model.encoder(torch.tensor(gene_ids, dtype=torch.long).to(device))\n",
    "gene_embeddings = gene_embeddings.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved gene embeddings for 1170 genes.\n"
     ]
    }
   ],
   "source": [
    "# Filter on the intersection between the Immune Human HVGs found in step 1.2 and scGPT's 30+K foundation model vocab\n",
    "gene_embeddings = {gene: gene_embeddings[i] for i, gene in enumerate(gene2idx.keys()) if gene in adata.var.index.tolist()}\n",
    "print('Retrieved gene embeddings for {} genes.'.format(len(gene_embeddings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1170/1170 [00:00<00:00, 2217503.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# Construct gene embedding network\n",
    "embed = GeneEmbedding(gene_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generates Numpy arrays of the gene embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a dictionary to store the gene embeddings\n",
    "gene_embeddings_dict = {}\n",
    "\n",
    "# Iterate over the gene embeddings\n",
    "for gene, embedding in gene_embeddings.items():\n",
    "    gene_embeddings_dict[gene] = embedding.tolist()\n",
    "\n",
    "# Create a pandas DataFrame from the dictionary\n",
    "gene_embeddings_df = pd.DataFrame.from_dict(gene_embeddings_dict, orient='index')\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "gene_embeddings_df.to_csv('gene_embeddings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Gene names as column headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a dictionary to store the gene embeddings\n",
    "gene_embeddings_dict = {}\n",
    "\n",
    "# Iterate over the gene embeddings\n",
    "for gene, embedding in gene_embeddings.items():\n",
    "    gene_embeddings_dict[gene] = embedding\n",
    "\n",
    "# Create a pandas DataFrame from the dictionary\n",
    "gene_embeddings_df = pd.DataFrame.from_dict(gene_embeddings_dict, orient='index')\n",
    "\n",
    "# Save the DataFrame as a space-separated CSV file with gene names as row indices\n",
    "gene_embeddings_df.to_csv('gene_embeddings_names_space_Separated.csv', sep=' ', header=False, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gene Embeddings with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'input_file.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m     gene_embeddings_dict[gene] \u001b[38;5;241m=\u001b[39m embedding\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Read the first row from the provided file\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_file.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     12\u001b[0m     labels \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreadline()\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Create a pandas DataFrame from the dictionary\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/nrnb/lib/python3.10/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'input_file.txt'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a dictionary to store the gene embeddings\n",
    "gene_embeddings_dict = {}\n",
    "\n",
    "# Iterate over the gene embeddings\n",
    "for gene, embedding in gene_embeddings.items():\n",
    "    gene_embeddings_dict[gene] = embedding\n",
    "\n",
    "# Read the first row from the provided file\n",
    "with open('input_file.txt', 'r') as f:\n",
    "    labels = f.readline().strip().split('\\t')\n",
    "\n",
    "# Create a pandas DataFrame from the dictionary\n",
    "gene_embeddings_df = pd.DataFrame.from_dict(gene_embeddings_dict, orient='index')\n",
    "\n",
    "# Set the column names using the labels\n",
    "gene_embeddings_df.columns = labels\n",
    "\n",
    "# Save the DataFrame as a CSV file with labels as column names\n",
    "gene_embeddings_df.to_csv('gene_embeddings_withLables.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'gene_embeddings_names.csv' has been processed and overwritten with modified content.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# Function to read CSV file, replace commas with spaces, and overwrite the original file\n",
    "def replace_commas_with_spaces(input_file):\n",
    "    temp_output_file = 'temp_output.csv'  # Temporary file to hold modified content\n",
    "\n",
    "    with open(input_file, 'r', newline='') as infile, open(temp_output_file, 'w', newline='') as outfile:\n",
    "        reader = csv.reader(infile)\n",
    "        writer = csv.writer(outfile, delimiter=' ')\n",
    "\n",
    "        for row in reader:\n",
    "            # Replace commas with spaces in each row\n",
    "            new_row = [entry.replace(',', ' ') for entry in row]\n",
    "            writer.writerow(new_row)\n",
    "\n",
    "    # Replace original file with temporary output file\n",
    "    os.replace(temp_output_file, input_file)\n",
    "    print(f\"CSV file '{input_file}' has been processed and overwritten with modified content.\")\n",
    "\n",
    "# Example usage\n",
    "input_filename = 'gene_embeddings_names.csv'   # Replace with your input CSV file name\n",
    "\n",
    "replace_commas_with_spaces(input_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blood model x Blood dataset work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume model from ../models/scGPT_Blood_model/scGPT_bc/best_model.pt, the model args will override the config ../models/scGPT_Blood_model/scGPT_bc/args.json.\n"
     ]
    }
   ],
   "source": [
    "# Specify model path; here we load the pre-trained scGPT blood model\n",
    "model_dir = Path(\"../models/scGPT_Blood_model/scGPT_bc\")\n",
    "model_config_file = model_dir / \"args.json\"\n",
    "model_file = model_dir / \"best_model.pt\"\n",
    "vocab_file = model_dir / \"vocab.json\"\n",
    "\n",
    "vocab = GeneVocab.from_file(vocab_file)\n",
    "for s in special_tokens:\n",
    "    if s not in vocab:\n",
    "        vocab.append_token(s)\n",
    "\n",
    "# Retrieve model parameters from config files\n",
    "with open(model_config_file, \"r\") as f:\n",
    "    model_configs = json.load(f)\n",
    "print(\n",
    "    f\"Resume model from {model_file}, the model args will override the \"\n",
    "    f\"config {model_config_file}.\"\n",
    ")\n",
    "embsize = model_configs[\"embsize\"]\n",
    "nhead = model_configs[\"nheads\"]\n",
    "d_hid = model_configs[\"d_hid\"]\n",
    "nlayers = model_configs[\"nlayers\"]\n",
    "n_layers_cls = model_configs[\"n_layers_cls\"]\n",
    "\n",
    "gene2idx = vocab.get_stoi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading params encoder.embedding.weight with shape torch.Size([36574, 512])\n",
      "Loading params encoder.enc_norm.weight with shape torch.Size([512])\n",
      "Loading params encoder.enc_norm.bias with shape torch.Size([512])\n",
      "Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])\n",
      "Loading params value_encoder.linear1.bias with shape torch.Size([512])\n",
      "Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params value_encoder.linear2.bias with shape torch.Size([512])\n",
      "Loading params value_encoder.norm.weight with shape torch.Size([512])\n",
      "Loading params value_encoder.norm.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])\n",
      "Loading params decoder.fc.0.weight with shape torch.Size([512, 512])\n",
      "Loading params decoder.fc.0.bias with shape torch.Size([512])\n",
      "Loading params decoder.fc.2.weight with shape torch.Size([512, 512])\n",
      "Loading params decoder.fc.2.bias with shape torch.Size([512])\n",
      "Loading params decoder.fc.4.weight with shape torch.Size([1, 512])\n",
      "Loading params decoder.fc.4.bias with shape torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (encoder): GeneEncoder(\n",
       "    (embedding): Embedding(36574, 512, padding_idx=36571)\n",
       "    (enc_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (value_encoder): ContinuousValueEncoder(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (linear1): Linear(in_features=1, out_features=512, bias=True)\n",
       "    (activation): ReLU()\n",
       "    (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.5, inplace=False)\n",
       "        (dropout2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): ExprDecoder(\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=512, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (cls_decoder): ClsDecoder(\n",
       "    (_decoder): ModuleList(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (out_layer): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       "  (sim): Similarity(\n",
       "    (cos): CosineSimilarity()\n",
       "  )\n",
       "  (creterion_cce): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "ntokens = len(vocab)  # size of vocabulary\n",
    "model = TransformerModel(\n",
    "    ntokens,\n",
    "    embsize,\n",
    "    nhead,\n",
    "    d_hid,\n",
    "    nlayers,\n",
    "    vocab=vocab,\n",
    "    pad_value=pad_value,\n",
    "    n_input_bins=n_input_bins,\n",
    ")\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load(model_file))\n",
    "    print(f\"Loading all model params from {model_file}\")\n",
    "except:\n",
    "    # only load params that are in the model and match the size\n",
    "    model_dict = model.state_dict()\n",
    "    pretrained_dict = torch.load(model_file)\n",
    "    pretrained_dict = {\n",
    "        k: v\n",
    "        for k, v in pretrained_dict.items()\n",
    "        if k in model_dict and v.shape == model_dict[k].shape\n",
    "    }\n",
    "    for k, v in pretrained_dict.items():\n",
    "        print(f\"Loading params {k} with shape {v.shape}\")\n",
    "        model_dict.update(pretrained_dict)\n",
    "        model.load_state_dict(model_dict)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "file_path = '../BEELINE-data/inputs/scRNA-Seq/mHSC-E/ExpressionData.csv'\n",
    "def load_and_preprocess_data(file_path):\n",
    "    df = pd.read_csv(file_path, index_col=0)\n",
    "    genes = df.index.tolist()\n",
    "    cells = df.columns.tolist()\n",
    "    expression_matrix = df.values.astype(float)  # Ensure values are floats\n",
    "    return genes, cells, expression_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_scgpt(genes, expression_matrix, gene2idx, n_input_bins=51):\n",
    "    data = []\n",
    "    unk_id = gene2idx.get('<unk>', len(gene2idx))  # Use the next available index if '<unk>' is not present\n",
    "    \n",
    "    for cell_expr in expression_matrix.T:  # Transpose to iterate over cells\n",
    "        nonzero_idx = np.nonzero(cell_expr)[0]\n",
    "        values = cell_expr[nonzero_idx]\n",
    "        \n",
    "        genes_cell = [genes[i] for i in nonzero_idx]\n",
    "        counts = values\n",
    "        \n",
    "        gene_ids = [gene2idx.get(gene, unk_id) for gene in genes_cell]\n",
    "        \n",
    "        # Normalize counts to input bins\n",
    "        norm_counts = (counts / np.max(counts) * (n_input_bins - 1)).astype(int) + 1\n",
    "        norm_counts = np.clip(norm_counts, 1, n_input_bins - 1)\n",
    "        \n",
    "        data.append({\n",
    "            'gene_ids': gene_ids,\n",
    "            'norm_counts': norm_counts.tolist()\n",
    "        })\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(model, data, device):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for cell in data:\n",
    "            gene_ids = torch.tensor(cell['gene_ids'], dtype=torch.long).unsqueeze(0).to(device)\n",
    "            norm_counts = torch.tensor(cell['norm_counts'], dtype=torch.long).unsqueeze(0).to(device)\n",
    "            \n",
    "            # Create src_key_padding_mask\n",
    "            src_key_padding_mask = torch.zeros_like(gene_ids, dtype=torch.bool).to(device)\n",
    "            \n",
    "            output = model(gene_ids, norm_counts, src_key_padding_mask=src_key_padding_mask)\n",
    "            embedding = output.mean(dim=1)  # Average over gene dimension\n",
    "            embeddings.append(embedding.cpu().numpy())\n",
    "    \n",
    "    return np.vstack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(model, data, device):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, cell in enumerate(data):\n",
    "            try:\n",
    "                gene_ids = torch.tensor(cell['gene_ids'], dtype=torch.long).unsqueeze(0).to(device)\n",
    "                norm_counts = torch.tensor(cell['norm_counts'], dtype=torch.long).unsqueeze(0).to(device)\n",
    "                \n",
    "                src_key_padding_mask = torch.zeros_like(gene_ids, dtype=torch.bool).to(device)\n",
    "                \n",
    "                output = model(gene_ids, norm_counts, src_key_padding_mask=src_key_padding_mask)\n",
    "                embedding = output.mean(dim=1)\n",
    "                embeddings.append(embedding.cpu().numpy())\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing cell {i}: {e}\")\n",
    "                print(f\"gene_ids shape: {gene_ids.shape}, norm_counts shape: {norm_counts.shape}\")\n",
    "                raise\n",
    "    \n",
    "    return np.vstack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m genes, cells, expression_matrix \u001b[38;5;241m=\u001b[39m load_and_preprocess_data(file_path)\n\u001b[1;32m      2\u001b[0m data \u001b[38;5;241m=\u001b[39m prepare_data_for_scgpt(genes, expression_matrix, gene2idx, n_input_bins)\n\u001b[0;32m----> 4\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Now 'embeddings' contains the gene embeddings for each cell\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated embeddings shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membeddings\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[28], line 7\u001b[0m, in \u001b[0;36mgenerate_embeddings\u001b[0;34m(model, data, device)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cell \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m----> 7\u001b[0m         gene_ids \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcell\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgene_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m         norm_counts \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(cell[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorm_counts\u001b[39m\u001b[38;5;124m'\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;66;03m# Create src_key_padding_mask\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "genes, cells, expression_matrix = load_and_preprocess_data(file_path)\n",
    "data = prepare_data_for_scgpt(genes, expression_matrix, gene2idx, n_input_bins)\n",
    "\n",
    "embeddings = generate_embeddings(model, data, device)\n",
    "\n",
    "# Now 'embeddings' contains the gene embeddings for each cell\n",
    "print(f\"Generated embeddings shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nrnb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
